{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cefe88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "import pickle\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c881dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_DEFAULT_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\n",
    "            \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s\",\n",
    "            \"datefmt\": \"%Y-%m-%d %H:%M:%S\",\n",
    "        },\n",
    "        \"simple\": {\"format\": \"%(message)s\"},\n",
    "    },\n",
    "    \"root\": {\"level\": \"DEBUG\"},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a1f3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3debdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function():\n",
    "    \"\"\"Dummy Function to test logging inside a function\"\"\"\n",
    "    logger.info(f\"Logging Test - Function Call Object Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18711e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logger(\n",
    "    logger=None, cfg=None, log_file=None, console=True, log_level=\"DEBUG\"\n",
    "):\n",
    "    \"\"\"Function to setup configurations of logger through function.\n",
    "\n",
    "    The individual arguments of `log_file`, `console`, `log_level` will overwrite the ones in cfg.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "            logger:\n",
    "                    Predefined logger object if present. If None a ew logger object will be created from root.\n",
    "            cfg: dict()\n",
    "                    Configuration of the logging to be implemented by default\n",
    "            log_file: str\n",
    "                    Path to the log file for logs to be stored\n",
    "            console: bool\n",
    "                    To include a console handler(logs printing in console)\n",
    "            log_level: str\n",
    "                    One of `[\"INFO\",\"DEBUG\",\"WARNING\",\"ERROR\",\"CRITICAL\"]`\n",
    "                    default - `\"DEBUG\"`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "    \"\"\"\n",
    "\n",
    "    if not cfg:\n",
    "        logging.config.dictConfig(LOGGING_DEFAULT_CONFIG)\n",
    "    else:\n",
    "        logging.config.dictConfig(cfg)\n",
    "\n",
    "    logger = logger or logging.getLogger()\n",
    "\n",
    "    if log_file or console:\n",
    "        for hdlr in logger.handlers:\n",
    "            logger.removeHandler(hdlr)\n",
    "\n",
    "        if log_file:\n",
    "            # if not os.path.exists()\n",
    "            # path = os.path.join(os.getcwd(), 'logs', log_file)\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setLevel(getattr(logging, log_level))\n",
    "            logger.addHandler(fh)\n",
    "\n",
    "        if console:\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setLevel(getattr(logging, log_level))\n",
    "            logger.addHandler(sh)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c32eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] dataset model score log_level log_console\n",
      "ipykernel_launcher.py: error: the following arguments are required: model, score, log_level, log_console\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anusha.polaki\\AppData\\Local\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"dataset\", type=str, help=\"Train_Test Data Folder\")\n",
    "parser.add_argument(\"model\", type=str, help=\"Model Folder\")\n",
    "parser.add_argument(\"score\", type=str, help=\"Score Output Folder\")\n",
    "parser.add_argument(\"log_level\", type=str, help=\"Log_level\")\n",
    "parser.add_argument(\"log_console\", type=bool, help=\"Log_console\")\n",
    "args = parser.parse_args()\n",
    "dataset_folder = args.dataset\n",
    "model_folder = args.model\n",
    "score_folder = args.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1646eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd(),'..', 'data', \"train_data.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd(),'..', 'data', \"test_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92086eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Loaded data\")\n",
    "linear_model = pickle.load(open(os.path.join(os.getcwd(),'..', 'notebooks', \"linear_model\"), \"rb\"))\n",
    "decisiontree_model = pickle.load(\n",
    "    open(os.path.join(os.getcwd(),'..', 'notebooks', \"decisiontree_model\"), \"rb\")\n",
    ")\n",
    "randomforest_model = pickle.load(\n",
    "    open(os.path.join(os.getcwd(),'..', 'notebooks', \"randomforest_model\"), \"rb\")\n",
    ")\n",
    "logger.debug(\"Loaded model\")\n",
    "lin_predictions = linear_model.predict(test_data.drop(columns=[\"median_house_value\"]))\n",
    "lin_mse = mean_squared_error(lin_predictions, test_data[\"median_house_value\"])\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "\n",
    "lin_mae = mean_absolute_error(lin_predictions, test_data[\"median_house_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b9e2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),'..','score', \"lin_score.txt\"), \"w\") as file1:\n",
    "    # Writing data to a file\n",
    "    file1.write(\"Test Scores\\n\")\n",
    "    file1.write(\"Root Mean Squared Error {}\".format(lin_rmse))\n",
    "    file1.write(\"\\n\")\n",
    "    file1.write(\"Mean Absolute Error {}\".format(lin_mae))\n",
    "    file1.write(\"\\n\")\n",
    "\n",
    "logger.debug(\"Written data\")\n",
    "tree_predictions = decisiontree_model.predict(\n",
    "    test_data.drop(columns=[\"median_house_value\"])\n",
    ")\n",
    "tree_mse = mean_squared_error(tree_predictions, test_data[\"median_house_value\"])\n",
    "tree_rmse = np.sqrt(tree_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45aa647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),'..','score', \"tree_score.txt\"), \"w\") as file2:\n",
    "    # Writing data to a file\n",
    "    file2.write(\"Decision Tree Scores\\n\")\n",
    "    file2.write(\"Root Mean Squared Error {}\".format(tree_rmse))\n",
    "    file2.write(\"\\n\")\n",
    "\n",
    "\n",
    "forest_predictions = randomforest_model.predict(\n",
    "    test_data.drop(columns=[\"median_house_value\"])\n",
    ")\n",
    "final_mse = mean_squared_error(forest_predictions, test_data[\"median_house_value\"])\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ac1676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),'..','score', \"forest_score.txt\"), \"w\") as file3:\n",
    "    file3.write(\"Random Forest Scores\\n\")\n",
    "    file3.write(\"Root_Mean_Squared_Score {}\".format(final_rmse))\n",
    "    file3.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913a134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
